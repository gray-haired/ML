{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Полиномиальная регрессия"
      ],
      "metadata": {
        "id": "zDwgsy0P5_hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "O_BjrUhf52ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet\n",
        "from sklearn.metrics import mean_squared_log_error"
      ],
      "metadata": {
        "id": "vyc_7Kqm4kET"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## получение данных"
      ],
      "metadata": {
        "id": "tuV3uN_56HYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/energy_data_2.csv')\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGz-rnoa4oyf",
        "outputId": "dee12937-6e40-4b3d-a84f-b11aa1d700d6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             timestamp  meter_reading  air_temperature  cloud_coverage  \\\n",
            "0  2016-01-30 08:00:00        43.6839              8.3             0.0   \n",
            "1  2016-01-31 05:00:00        37.5408             12.8             0.0   \n",
            "2  2016-01-31 17:00:00        52.5571             20.6             0.0   \n",
            "3  2016-04-08 14:00:00        59.3827             21.7             2.0   \n",
            "4  2016-05-01 19:00:00       448.0000             31.1             0.0   \n",
            "\n",
            "   dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_speed  \\\n",
            "0              6.1                0.0              1019.0         2.1   \n",
            "1             10.0                0.0              1021.9         0.0   \n",
            "2             11.7                0.0              1020.9         1.5   \n",
            "3             14.4                0.0              1015.1         3.1   \n",
            "4             17.2                0.0              1016.1         4.1   \n",
            "\n",
            "   wind_direction_sin  wind_direction_cos  air_temperature1  hour  \n",
            "0        5.877853e-01        8.090170e-01              -2.3     8  \n",
            "1        0.000000e+00        1.000000e+00              -1.1     5  \n",
            "2       -3.090170e-01       -9.510565e-01               1.7    17  \n",
            "3        1.000000e+00        1.194340e-15               2.8    14  \n",
            "4        1.224647e-16       -1.000000e+00               1.1    19  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## получение факторов второго порядка"
      ],
      "metadata": {
        "id": "gjjyDT0F6RI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_iterate = data.columns\n",
        "columns = list(data.columns)\n",
        "for column1 in columns_iterate:\n",
        "  for column2 in columns_iterate:\n",
        "    if (column1 not in ['timestamp', 'meter_reading'] and \n",
        "        column2 not in ['timestamp', 'meter_reading']): \n",
        "        c = column1 + '_' + column2 \n",
        "        data[c] = np.multiply(data[column1], data[column2]) \n",
        "        columns.append(c)\n",
        "columns.remove('timestamp')\n",
        "columns.remove('meter_reading')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHJ3G08G63Gs",
        "outputId": "c5b559dd-7c80-45f8-c539-aa5e6a9f4f87"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## нормализация данных"
      ],
      "metadata": {
        "id": "50Xd2W_f8i7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_norm = MinMaxScaler().fit_transform(data[columns])"
      ],
      "metadata": {
        "id": "lSj_FEjU8g2B"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Модель линейной регрессии"
      ],
      "metadata": {
        "id": "5F8goRiS82kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmsle_err (y, y_pred):\n",
        "  return((np.log(1 + y) - np.log(1 + y_pred))**2).mean()**0.5"
      ],
      "metadata": {
        "id": "38yd3t6g82DX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = data_norm\n",
        "y = data['meter_reading']\n",
        "model = LinearRegression().fit(x, y)\n",
        "print('RMSLE: {0:.5}'.format(rmsle_err(y, model.predict(x))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxE-9l2C9U7Q",
        "outputId": "8650f8c7-a31b-44fd-c130-fdd49e22d77a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSLE: 0.18903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Оптимизация гиперпараметров"
      ],
      "metadata": {
        "id": "7szvqj8iGP5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## использование Optuna"
      ],
      "metadata": {
        "id": "a9TvV8RlGT-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective (trial):\n",
        "  alpha = trial.suggest_float('alpha', 1e-8, 1, log = True)\n",
        "  l1_ratio = trial.suggest_float('l1_ratio', 1e-3, 1, log = True)\n",
        "  regressor_obj = ElasticNet(alpha = alpha, l1_ratio = l1_ratio, max_iter = 1000)\n",
        "  regressor_obj.fit(x, y)\n",
        "  y_pred = regressor_obj.predict(x)\n",
        "  return mean_squared_log_error(y, y_pred)"
      ],
      "metadata": {
        "id": "jjd3g4PZGY5o"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(objective, n_trials = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVQIX6yhRvMI",
        "outputId": "1b57f046-42a6-42f3-a2c6-f40a9c6aafc5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-05-22 10:23:50,158]\u001b[0m A new study created in memory with name: no-name-d3221010-1913-47de-b685-7ade4381c47d\u001b[0m\n",
            "\u001b[32m[I 2022-05-22 10:23:50,204]\u001b[0m Trial 0 finished with value: 0.0499277605231467 and parameters: {'alpha': 0.3003485783923512, 'l1_ratio': 0.002412119675239047}. Best is trial 0 with value: 0.0499277605231467.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:51,302]\u001b[0m Trial 1 finished with value: 0.03762718867086002 and parameters: {'alpha': 2.1371804577260404e-07, 'l1_ratio': 0.017598527847859084}. Best is trial 1 with value: 0.03762718867086002.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.504e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:51,935]\u001b[0m Trial 2 finished with value: 0.03772653043874018 and parameters: {'alpha': 7.9144707339489e-05, 'l1_ratio': 0.6776127636653178}. Best is trial 1 with value: 0.03762718867086002.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.571e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:52,756]\u001b[0m Trial 3 finished with value: 0.03763221719093574 and parameters: {'alpha': 6.890331946739721e-07, 'l1_ratio': 0.04173713750569112}. Best is trial 1 with value: 0.03762718867086002.\u001b[0m\n",
            "\u001b[32m[I 2022-05-22 10:23:53,429]\u001b[0m Trial 4 finished with value: 0.03958652891033264 and parameters: {'alpha': 0.0035456872724520636, 'l1_ratio': 0.031796494627249657}. Best is trial 1 with value: 0.03762718867086002.\u001b[0m\n",
            "\u001b[32m[I 2022-05-22 10:23:53,496]\u001b[0m Trial 5 finished with value: 0.045320092784906556 and parameters: {'alpha': 0.12167987293194113, 'l1_ratio': 0.06461849435236398}. Best is trial 1 with value: 0.03762718867086002.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:54,219]\u001b[0m Trial 6 finished with value: 0.037647992226920425 and parameters: {'alpha': 4.089363527721084e-06, 'l1_ratio': 0.4396873589693077}. Best is trial 1 with value: 0.03762718867086002.\u001b[0m\n",
            "\u001b[32m[I 2022-05-22 10:23:54,584]\u001b[0m Trial 7 finished with value: 0.040640788283167834 and parameters: {'alpha': 0.009325429629878128, 'l1_ratio': 0.057456257995762386}. Best is trial 1 with value: 0.03762718867086002.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.155e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:55,234]\u001b[0m Trial 8 finished with value: 0.038031553399360984 and parameters: {'alpha': 0.00039328328636344654, 'l1_ratio': 0.35640444176399283}. Best is trial 1 with value: 0.03762718867086002.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.592e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:55,938]\u001b[0m Trial 9 finished with value: 0.03778504021803329 and parameters: {'alpha': 7.437176954379972e-05, 'l1_ratio': 0.019271312851108304}. Best is trial 1 with value: 0.03762718867086002.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:56,567]\u001b[0m Trial 10 finished with value: 0.037624895547758594 and parameters: {'alpha': 1.2179897425136392e-08, 'l1_ratio': 0.0033526879653627928}. Best is trial 10 with value: 0.037624895547758594.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:57,184]\u001b[0m Trial 11 finished with value: 0.03762487045630074 and parameters: {'alpha': 1.0021741969560093e-08, 'l1_ratio': 0.0028317204306567206}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:57,834]\u001b[0m Trial 12 finished with value: 0.03762492117671726 and parameters: {'alpha': 1.4347444228868023e-08, 'l1_ratio': 0.0011297133669689848}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:58,466]\u001b[0m Trial 13 finished with value: 0.03762517100099406 and parameters: {'alpha': 3.586254845032877e-08, 'l1_ratio': 0.004027186377433673}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.576e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:59,132]\u001b[0m Trial 14 finished with value: 0.03766048999016851 and parameters: {'alpha': 3.936319063868163e-06, 'l1_ratio': 0.006804467839941912}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:23:59,778]\u001b[0m Trial 15 finished with value: 0.03762616203328886 and parameters: {'alpha': 1.210657576931505e-07, 'l1_ratio': 0.0010017986253480712}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:00,430]\u001b[0m Trial 16 finished with value: 0.03765042058648811 and parameters: {'alpha': 2.6134307975308072e-06, 'l1_ratio': 0.008067447440945008}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:01,085]\u001b[0m Trial 17 finished with value: 0.037624936531548005 and parameters: {'alpha': 1.568142609535679e-08, 'l1_ratio': 0.002345342748278922}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:01,747]\u001b[0m Trial 18 finished with value: 0.03762592826072101 and parameters: {'alpha': 1.0150271092130091e-07, 'l1_ratio': 0.007130108250136621}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.577e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:02,379]\u001b[0m Trial 19 finished with value: 0.03770665628069749 and parameters: {'alpha': 1.7131258097174305e-05, 'l1_ratio': 0.12738415432798159}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.571e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:03,531]\u001b[0m Trial 20 finished with value: 0.03763210867344843 and parameters: {'alpha': 6.51955589169414e-07, 'l1_ratio': 0.0024089898264527372}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:04,196]\u001b[0m Trial 21 finished with value: 0.03762488020126182 and parameters: {'alpha': 1.0838891827559184e-08, 'l1_ratio': 0.0011205378871667281}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:04,984]\u001b[0m Trial 22 finished with value: 0.03762532533685244 and parameters: {'alpha': 4.90207976093953e-08, 'l1_ratio': 0.0014548008348844307}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:05,763]\u001b[0m Trial 23 finished with value: 0.03762495354286355 and parameters: {'alpha': 1.7158103604235946e-08, 'l1_ratio': 0.0033915331021856327}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.571e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:06,441]\u001b[0m Trial 24 finished with value: 0.03763121685143845 and parameters: {'alpha': 5.715998902692305e-07, 'l1_ratio': 0.00524542327168246}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:07,115]\u001b[0m Trial 25 finished with value: 0.037624908002064514 and parameters: {'alpha': 1.322920111553581e-08, 'l1_ratio': 0.0018814301458956468}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.570e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:07,804]\u001b[0m Trial 26 finished with value: 0.037628047901250336 and parameters: {'alpha': 2.894170478821089e-07, 'l1_ratio': 0.014815880759835838}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:08,787]\u001b[0m Trial 27 finished with value: 0.03762556531636463 and parameters: {'alpha': 7.030647731041214e-08, 'l1_ratio': 0.010776157792834412}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.573e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:09,694]\u001b[0m Trial 28 finished with value: 0.03764103719503944 and parameters: {'alpha': 1.5357197595934465e-06, 'l1_ratio': 0.004254815873667119}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "\u001b[32m[I 2022-05-22 10:24:09,755]\u001b[0m Trial 29 finished with value: 0.04924323624833486 and parameters: {'alpha': 0.2664905493106128, 'l1_ratio': 0.0030144034579996275}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.581e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:10,417]\u001b[0m Trial 30 finished with value: 0.03770733331708413 and parameters: {'alpha': 1.5337346270507723e-05, 'l1_ratio': 0.0018115749190869244}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:11,033]\u001b[0m Trial 31 finished with value: 0.037624910984416456 and parameters: {'alpha': 1.3483617901562552e-08, 'l1_ratio': 0.0017960970713628438}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:11,918]\u001b[0m Trial 32 finished with value: 0.037625268217754346 and parameters: {'alpha': 4.412173524609821e-08, 'l1_ratio': 0.001602184130819114}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:12,568]\u001b[0m Trial 33 finished with value: 0.03762632255059673 and parameters: {'alpha': 1.3514113198989917e-07, 'l1_ratio': 0.0024453422536794087}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:13,773]\u001b[0m Trial 34 finished with value: 0.0376248819643587 and parameters: {'alpha': 1.0990236277821887e-08, 'l1_ratio': 0.0011573073391457007}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.570e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:14,384]\u001b[0m Trial 35 finished with value: 0.037628003146826974 and parameters: {'alpha': 2.815078708799559e-07, 'l1_ratio': 0.001041888436531033}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:15,147]\u001b[0m Trial 36 finished with value: 0.03762519206162451 and parameters: {'alpha': 3.770087348939784e-08, 'l1_ratio': 0.004727420171004461}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:15,868]\u001b[0m Trial 37 finished with value: 0.03762742549675723 and parameters: {'alpha': 2.3325381366244908e-07, 'l1_ratio': 0.01129901004349334}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "\u001b[32m[I 2022-05-22 10:24:16,587]\u001b[0m Trial 38 finished with value: 0.04005830324209967 and parameters: {'alpha': 0.0053762787596279395, 'l1_ratio': 0.0014655262970116288}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "\u001b[32m[I 2022-05-22 10:24:17,274]\u001b[0m Trial 39 finished with value: 0.041670131202748616 and parameters: {'alpha': 0.02253515935629975, 'l1_ratio': 0.13212868337301756}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.040e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:18,071]\u001b[0m Trial 40 finished with value: 0.03859801573824755 and parameters: {'alpha': 0.0010044373752994748, 'l1_ratio': 0.02240364779041197}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:18,806]\u001b[0m Trial 41 finished with value: 0.03762487114470024 and parameters: {'alpha': 1.0076048182034503e-08, 'l1_ratio': 0.002362200425348914}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:19,435]\u001b[0m Trial 42 finished with value: 0.03762488044987924 and parameters: {'alpha': 1.0877623119876679e-08, 'l1_ratio': 0.0027290315429285834}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:20,144]\u001b[0m Trial 43 finished with value: 0.03762516926257137 and parameters: {'alpha': 3.566273795941756e-08, 'l1_ratio': 0.002617729320362116}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:20,842]\u001b[0m Trial 44 finished with value: 0.037625062754382405 and parameters: {'alpha': 2.6483597779381397e-08, 'l1_ratio': 0.001375653963534077}. Best is trial 11 with value: 0.03762487045630074.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:21,511]\u001b[0m Trial 45 finished with value: 0.03762487008632559 and parameters: {'alpha': 1.0012764537006e-08, 'l1_ratio': 0.005106262753952575}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:22,219]\u001b[0m Trial 46 finished with value: 0.037625554228134364 and parameters: {'alpha': 6.898027219779217e-08, 'l1_ratio': 0.005545153830775738}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:22,900]\u001b[0m Trial 47 finished with value: 0.03762644376021393 and parameters: {'alpha': 1.4581949222753402e-07, 'l1_ratio': 0.003606471525208311}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.572e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:23,750]\u001b[0m Trial 48 finished with value: 0.037635449937117295 and parameters: {'alpha': 9.678883478996837e-07, 'l1_ratio': 0.002195701324539426}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:24,786]\u001b[0m Trial 49 finished with value: 0.03762507856789248 and parameters: {'alpha': 2.8064475901366506e-08, 'l1_ratio': 0.009414685564313421}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:25,702]\u001b[0m Trial 50 finished with value: 0.03768803938677166 and parameters: {'alpha': 8.801886497641089e-06, 'l1_ratio': 0.0062614488746109845}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:26,394]\u001b[0m Trial 51 finished with value: 0.03762489098977162 and parameters: {'alpha': 1.1762518239326244e-08, 'l1_ratio': 0.0011186699959562039}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:27,064]\u001b[0m Trial 52 finished with value: 0.03762504075349217 and parameters: {'alpha': 2.4637424202633277e-08, 'l1_ratio': 0.0030022084057873826}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:27,774]\u001b[0m Trial 53 finished with value: 0.03762548880540832 and parameters: {'alpha': 6.306839431490642e-08, 'l1_ratio': 0.001412090001354348}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:28,747]\u001b[0m Trial 54 finished with value: 0.037624873324506446 and parameters: {'alpha': 1.0259110452271217e-08, 'l1_ratio': 0.0019936505659198505}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:29,389]\u001b[0m Trial 55 finished with value: 0.03762591273224834 and parameters: {'alpha': 9.982231875427247e-08, 'l1_ratio': 0.0038046799293843846}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.605e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:30,010]\u001b[0m Trial 56 finished with value: 0.03787230819383859 and parameters: {'alpha': 0.0001303113476324789, 'l1_ratio': 0.002229238334779586}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:30,632]\u001b[0m Trial 57 finished with value: 0.03762503512426089 and parameters: {'alpha': 2.490304906350955e-08, 'l1_ratio': 0.03310821641562699}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.570e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:31,780]\u001b[0m Trial 58 finished with value: 0.03762943333578862 and parameters: {'alpha': 4.085940643797709e-07, 'l1_ratio': 0.0019645234441304734}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:32,688]\u001b[0m Trial 59 finished with value: 0.03762487615495801 and parameters: {'alpha': 1.0512036743253463e-08, 'l1_ratio': 0.0029854911223815015}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:33,318]\u001b[0m Trial 60 finished with value: 0.03762669285923107 and parameters: {'alpha': 1.683135397370069e-07, 'l1_ratio': 0.008579015108355464}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:33,942]\u001b[0m Trial 61 finished with value: 0.03762488823656941 and parameters: {'alpha': 1.154888848654408e-08, 'l1_ratio': 0.0030367644583119417}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:34,754]\u001b[0m Trial 62 finished with value: 0.03762500361149793 and parameters: {'alpha': 2.1470334038412035e-08, 'l1_ratio': 0.004011151391986355}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:35,443]\u001b[0m Trial 63 finished with value: 0.03762487637559214 and parameters: {'alpha': 1.0527839615463712e-08, 'l1_ratio': 0.002688789366528587}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:36,081]\u001b[0m Trial 64 finished with value: 0.037625357365543705 and parameters: {'alpha': 5.1962508320730834e-08, 'l1_ratio': 0.005123820581559268}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:36,875]\u001b[0m Trial 65 finished with value: 0.03762500016682374 and parameters: {'alpha': 2.1126060394987388e-08, 'l1_ratio': 0.0017257209270028157}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:37,725]\u001b[0m Trial 66 finished with value: 0.037625697549153334 and parameters: {'alpha': 8.147885840002716e-08, 'l1_ratio': 0.006886912699984675}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:38,353]\u001b[0m Trial 67 finished with value: 0.037625284741919424 and parameters: {'alpha': 4.552627798337112e-08, 'l1_ratio': 0.0012806041620771083}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:39,034]\u001b[0m Trial 68 finished with value: 0.03762497663494256 and parameters: {'alpha': 1.911752617754048e-08, 'l1_ratio': 0.002182195838890707}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:39,682]\u001b[0m Trial 69 finished with value: 0.03762561848885163 and parameters: {'alpha': 8.119066655070209e-08, 'l1_ratio': 0.08744866052974631}. Best is trial 45 with value: 0.03762487008632559.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:40,292]\u001b[0m Trial 70 finished with value: 0.037624844596084894 and parameters: {'alpha': 1.0266162103887965e-08, 'l1_ratio': 0.24289897076152217}. Best is trial 70 with value: 0.037624844596084894.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:40,933]\u001b[0m Trial 71 finished with value: 0.03762476124988513 and parameters: {'alpha': 3.1390902705839214e-08, 'l1_ratio': 0.9828716637293764}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:41,563]\u001b[0m Trial 72 finished with value: 0.03762491737961535 and parameters: {'alpha': 2.0125806418415402e-08, 'l1_ratio': 0.3052636824371378}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:42,758]\u001b[0m Trial 73 finished with value: 0.037624995087971534 and parameters: {'alpha': 3.8218998595550214e-08, 'l1_ratio': 0.461403623444901}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:43,800]\u001b[0m Trial 74 finished with value: 0.03762478279072906 and parameters: {'alpha': 1.1341184783385071e-08, 'l1_ratio': 0.7826951946327463}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "\u001b[32m[I 2022-05-22 10:24:43,833]\u001b[0m Trial 75 finished with value: 0.05235244368672959 and parameters: {'alpha': 0.8443168037282517, 'l1_ratio': 0.5926829439095127}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:44,467]\u001b[0m Trial 76 finished with value: 0.03762483293994805 and parameters: {'alpha': 3.297378849498583e-08, 'l1_ratio': 0.7973430118022083}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:45,102]\u001b[0m Trial 77 finished with value: 0.03762486501220782 and parameters: {'alpha': 3.42907268501375e-08, 'l1_ratio': 0.7250018962960565}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.567e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:45,716]\u001b[0m Trial 78 finished with value: 0.03762496144269765 and parameters: {'alpha': 2.163115770052329e-07, 'l1_ratio': 0.921468177711377}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:46,376]\u001b[0m Trial 79 finished with value: 0.03762496418508523 and parameters: {'alpha': 1.1284916877903765e-07, 'l1_ratio': 0.8437519698878847}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:47,072]\u001b[0m Trial 80 finished with value: 0.03762508682563054 and parameters: {'alpha': 3.8570127131969346e-08, 'l1_ratio': 0.2619254430812491}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:47,725]\u001b[0m Trial 81 finished with value: 0.03762480930966502 and parameters: {'alpha': 1.690129688227366e-08, 'l1_ratio': 0.7208505763511162}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:48,714]\u001b[0m Trial 82 finished with value: 0.03762482133289097 and parameters: {'alpha': 1.8098628541475082e-08, 'l1_ratio': 0.6825714144285551}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:49,742]\u001b[0m Trial 83 finished with value: 0.03762481114913104 and parameters: {'alpha': 1.741992766479719e-08, 'l1_ratio': 0.720218763066996}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:50,436]\u001b[0m Trial 84 finished with value: 0.03762486417887462 and parameters: {'alpha': 3.054412405503597e-08, 'l1_ratio': 0.6931277255693747}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:51,059]\u001b[0m Trial 85 finished with value: 0.03762493577760987 and parameters: {'alpha': 5.10975482849523e-08, 'l1_ratio': 0.6978571525726346}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:51,818]\u001b[0m Trial 86 finished with value: 0.03762486039204621 and parameters: {'alpha': 1.8324286717652706e-08, 'l1_ratio': 0.5035830810408434}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:52,504]\u001b[0m Trial 87 finished with value: 0.03762699624303604 and parameters: {'alpha': 3.9150444886356424e-07, 'l1_ratio': 0.5086553069615496}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:53,206]\u001b[0m Trial 88 finished with value: 0.03762488213312617 and parameters: {'alpha': 1.8176921601691637e-08, 'l1_ratio': 0.39684648474313405}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:53,876]\u001b[0m Trial 89 finished with value: 0.037624761506409546 and parameters: {'alpha': 7.561804954880522e-08, 'l1_ratio': 0.9949139636839}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:54,513]\u001b[0m Trial 90 finished with value: 0.03762621229747305 and parameters: {'alpha': 1.6242741064261828e-07, 'l1_ratio': 0.22966700464654807}. Best is trial 71 with value: 0.03762476124988513.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:55,179]\u001b[0m Trial 91 finished with value: 0.03762475703311751 and parameters: {'alpha': 1.744644794902429e-08, 'l1_ratio': 0.9867695990378265}. Best is trial 91 with value: 0.03762475703311751.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:55,831]\u001b[0m Trial 92 finished with value: 0.03762513553993966 and parameters: {'alpha': 7.37780035101663e-08, 'l1_ratio': 0.5593352135488778}. Best is trial 91 with value: 0.03762475703311751.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:56,461]\u001b[0m Trial 93 finished with value: 0.037624757204633555 and parameters: {'alpha': 1.7669707862025137e-08, 'l1_ratio': 0.9861532716023755}. Best is trial 91 with value: 0.03762475703311751.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:57,118]\u001b[0m Trial 94 finished with value: 0.03762476340619359 and parameters: {'alpha': 1.6465060753710994e-08, 'l1_ratio': 0.9525273158809805}. Best is trial 91 with value: 0.03762475703311751.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:57,755]\u001b[0m Trial 95 finished with value: 0.03762476421033645 and parameters: {'alpha': 5.238694270584086e-08, 'l1_ratio': 0.9864714067560184}. Best is trial 91 with value: 0.03762475703311751.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:58,387]\u001b[0m Trial 96 finished with value: 0.03762477566205192 and parameters: {'alpha': 6.168678621432802e-08, 'l1_ratio': 0.9731684963682159}. Best is trial 91 with value: 0.03762475703311751.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:59,022]\u001b[0m Trial 97 finished with value: 0.03762482343607958 and parameters: {'alpha': 1.1993806673124407e-07, 'l1_ratio': 0.9539373419938441}. Best is trial 91 with value: 0.03762475703311751.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:24:59,798]\u001b[0m Trial 98 finished with value: 0.03762478654743397 and parameters: {'alpha': 5.501763371475622e-08, 'l1_ratio': 0.9524316873311268}. Best is trial 91 with value: 0.03762475703311751.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.563e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "\u001b[32m[I 2022-05-22 10:25:00,786]\u001b[0m Trial 99 finished with value: 0.03762489329934363 and parameters: {'alpha': 1.2960117713037977e-06, 'l1_ratio': 0.9946438354634392}. Best is trial 91 with value: 0.03762475703311751.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_optuna = ElasticNet(alpha = study.best_params['alpha'], \n",
        "                          l1_ratio = study.best_params['l1_ratio'], max_iter = 1000).fit(x, y)\n",
        "print('RMSLE: {0:.5}'.format(rmsle_err(y, model_optuna.predict(x))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twzYCfZ7TM38",
        "outputId": "d68cfe8a-2f68-4e02-c25e-f7bb6abac281"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSLE: 0.19397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e+06, tolerance: 1.306e+03\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "lsn_17_CW_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}